{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4382c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import rospy\n",
    "from centermask.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2_ros.msg import Result\n",
    "from sensor_msgs.msg import Image, CompressedImage, RegionOfInterest\n",
    "import matplotlib.pyplot as plt\n",
    "import message_filters\n",
    "import pyrealsense2 as rs2\n",
    "from sensor_msgs.msg import CameraInfo\n",
    "\n",
    "import centermask.modeling.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2_ros.msg import PersonPositions, PersonPosition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(param, default=None):\n",
    "    new_param = rospy.get_param(param, default)\n",
    "    rospy.loginfo(\"[Centermask2] %s: %s\", param, new_param)\n",
    "    return new_param\n",
    "\n",
    "def convert_to_cv_image(image_msg):\n",
    "\n",
    "    if image_msg is None:\n",
    "        return None\n",
    "\n",
    "    channels = int(len(image_msg.data) / (image_msg.width * image_msg.height))\n",
    "\n",
    "    encoding = None\n",
    "    if image_msg.encoding.lower() in ['rgb8', 'bgr8']:\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == 'mono8':\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "    # For depth images        \n",
    "        encoding = np.uint16\n",
    "        channels = 1\n",
    "    elif image_msg.encoding.lower() == '32fc1':\n",
    "        encoding = np.float32\n",
    "        channels = 1\n",
    "\n",
    "    cv_img = np.ndarray(shape=(image_msg.height, image_msg.width, channels),\n",
    "                        dtype=encoding, buffer=image_msg.data)\n",
    "\n",
    "    if image_msg.encoding.lower() == 'mono8':\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "        pass\n",
    "    else:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_img\n",
    "\n",
    "def convert_compressed_to_cv_image(image_msg):\n",
    "\n",
    "    # 'msg' as type CompressedImage\n",
    "    depth_fmt, compr_type = image_msg.format.split(';')\n",
    "    # remove white space\n",
    "    depth_fmt = depth_fmt.strip()\n",
    "    compr_type = compr_type.strip()\n",
    "\n",
    "    if image_msg is None:\n",
    "        return None\n",
    "\n",
    "    encoding = None\n",
    "    if depth_fmt.lower() in ['rgb8', 'bgr8']:\n",
    "        encoding = np.uint8\n",
    "    elif depth_fmt.lower() == 'mono8':\n",
    "        encoding = np.uint8\n",
    "    elif depth_fmt.lower() == '16uc1':\n",
    "    # For depth images        \n",
    "        encoding = np.uint8\n",
    "        channels = 1\n",
    "    elif depth_fmt.lower() == '32fc1':\n",
    "        encoding = np.float32\n",
    "        channels = 1\n",
    "\n",
    "    cv_img = np.frombuffer(image_msg.data, encoding)\n",
    "    \n",
    "    if depth_fmt.lower() == '16uc1':\n",
    "        cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "\n",
    "                             \n",
    "    if depth_fmt.lower() == 'mono8':\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)\n",
    "    elif depth_fmt.lower() == '16uc1':\n",
    "        pass\n",
    "    else:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_img\n",
    "\n",
    "def getStaticDepthImage(depth_image, predictions, class_names):\n",
    "\n",
    "    static_depth_img = depth_image.copy()\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((15,15),np.uint8)\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "#         static_depth_img[masks[inds[i]]]=0\n",
    "        static_depth_img[(cv.dilate(np.float32(masks[inds[i]]),kernel,iterations = 2)).astype(bool)]=0\n",
    "\n",
    "    return static_depth_img\n",
    "\n",
    "def getResult(predictions, header, bridge, class_names):\n",
    "\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    result_msg = Result()\n",
    "    result_msg.header = header\n",
    "    result_msg.class_ids = class_ids[arr]\n",
    "    result_msg.class_names = class_names[arr]\n",
    "    result_msg.scores = scores[arr]\n",
    "\n",
    "#     for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "\n",
    "#     for i in inds:\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "        mask = np.zeros(masks[i].shape, dtype=\"uint8\")\n",
    "        mask[masks[i, :, :]]=255\n",
    "        mask = bridge.cv2_to_imgmsg(mask)\n",
    "        result_msg.masks.append(mask)\n",
    "\n",
    "        box = RegionOfInterest()\n",
    "        box.x_offset = np.uint32(x1)\n",
    "        box.y_offset = np.uint32(y1)\n",
    "        box.height = np.uint32(y2 - y1)\n",
    "        box.width = np.uint32(x2 - x1)\n",
    "        result_msg.boxes.append(box)\n",
    "\n",
    "    return result_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('centermask2_ros')\n",
    "\n",
    "bridge = CvBridge()\n",
    "_last_rgb_msg = None\n",
    "_last_depth_msg = None\n",
    "_msg_lock = threading.Lock()\n",
    "_image_counter = 0\n",
    "\n",
    "cfg = get_cfg()\n",
    "# cfg.merge_from_file(load_param('~config'))\n",
    "# cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_V_99_eSE_FPN_ms_3x.yaml\")\n",
    "cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = load_param('~detection_threshold') # set threshold for this model\n",
    "# cfg.MODEL.WEIGHTS = load_param('~model')\n",
    "# cfg.MODEL.WEIGHTS = \"/root/centermask2-V-99-eSE-FPN-ms-3x.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"/root/centermask2-lite-V-39-eSE-FPN-ms-4x.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "_class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).get(\"thing_classes\", None)\n",
    "\n",
    "_visualization = load_param('~visualization',True)\n",
    "_result_pub = rospy.Publisher('result', Result, queue_size=1)\n",
    "_vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)\n",
    "\n",
    "\n",
    "callback_init = False\n",
    "\n",
    "def callback_images(rgb_msg, depth_msg):\n",
    "    rospy.logdebug(\"Get an image\")\n",
    "    if _msg_lock.acquire(False):\n",
    "        _last_rgb_msg = rgb_msg\n",
    "        _last_depth_msg = depth_msg\n",
    "        _rgb_header = rgb_msg.header\n",
    "        _depth_header = depth_msg.header\n",
    "        _msg_lock.release()\n",
    "    callback_init = True\n",
    "        \n",
    "# _sub = rospy.Subscriber(load_param('~input'), Image, callback_image, queue_size=1)\n",
    "# _image_sub = rospy.Subscriber('/camera/color/image_raw', Image, callback_image, queue_size=1)\n",
    "# _depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw', Image, callback_image, queue_size=1)\n",
    "\n",
    "# _image_sub = message_filters.Subscriber('/camera/color/image_raw', CompressedImage)\n",
    "# _depth_sub = message_filters.Subscriber('/camera/depth/image_rect_raw', CompressedImage)\n",
    "        \n",
    "# ts = message_filters.ApproximateTimeSynchronizer([_image_sub, _depth_sub], 1, 0.003)\n",
    "# ts.registerCallback(callback_images)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "_last_rgb_msg_raw = rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None)\n",
    "_last_depth_msg_raw = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw', Image, timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convert_to_cv_image(_last_depth_msg_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd277189",
   "metadata": {},
   "outputs": [],
   "source": [
    "_last_rgb_msg = rospy.wait_for_message('/camera/color/image_raw/compressed', CompressedImage, timeout=None)\n",
    "_last_depth_msg = rospy.wait_for_message('/camera/depth/image_rect_raw/compressed', CompressedImage, timeout=None)\n",
    "_last_compresseddepth_msg = rospy.wait_for_message('/camera/depth/image_rect_raw/compressedDepth', CompressedImage, timeout=None)\n",
    "# _last_depth_msg = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw/compressed', CompressedImage, timeout=None)\n",
    "_rgb_header = _last_rgb_msg.header\n",
    "_depth_header = _last_depth_msg.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b57bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = _last_rgb_msg.header.stamp - _last_depth_msg.header.stamp\n",
    "dur.to_sec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img = np.frombuffer(_last_compresseddepth_msg.data, np.uint16)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4916822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'msg' as type CompressedImage\n",
    "depth_fmt, compr_type = _last_compresseddepth_msg.format.split(';')\n",
    "# remove white space\n",
    "depth_fmt = depth_fmt.strip()\n",
    "compr_type = compr_type.strip()\n",
    "if compr_type != \"compressedDepth\":\n",
    "    raise Exception(\"Compression type is not 'compressedDepth'.\"\n",
    "                    \"You probably subscribed to the wrong topic.\")\n",
    "\n",
    "# remove header from raw data\n",
    "depth_header_size = 12\n",
    "raw_data = _last_compresseddepth_msg.data[depth_header_size:]\n",
    "\n",
    "depth_img_raw = cv.imdecode(np.frombuffer(raw_data, np.uint8), cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For depth images        \n",
    "encoding = np.uint16\n",
    "channels = 1\n",
    "\n",
    "cv_img = np.frombuffer(_last_depth_msg.data, np.uint8)\n",
    "# cv_img.dtype = np.uint16\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if depth_fmt.lower() == '16uc1':\n",
    "#     cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)\n",
    "# else:\n",
    "#     cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "\n",
    "        \n",
    "cv_img = np.ndarray(shape=(480, 640, channels),\n",
    "                    dtype=encoding, buffer=_last_depth_msg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95711f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "\n",
    "ax1.imshow(convert_to_cv_image(_last_depth_msg_raw))\n",
    "ax1.set_title(\"Raw\")\n",
    "ax2.imshow(depth_img_raw)\n",
    "ax2.set_title(\"CompressedDepth\")\n",
    "ax3.imshow(convert_compressed_to_cv_image(_last_depth_msg))\n",
    "ax3.set_title(\"Compressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('depth_compression_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835bb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_transport import SubscriberFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ca688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2fe4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(bridge.compressed_imgmsg_to_cv2(_last_depth_msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c78ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bridge.compressed_imgmsg_to_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10212ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = rospy.wait_for_message('/depth', Image, timeout=None)\n",
    "plt.imshow(convert_to_cv_image(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'msg' as type CompressedImage\n",
    "depth_fmt, compr_type = _last_depth_msg.format.split(';')\n",
    "# remove white space\n",
    "depth_fmt = depth_fmt.strip()\n",
    "compr_type = compr_type.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imdecode(_last_rgb_msg, cv.CV_LOAD_IMAGE_UNCHANGED)\n",
    "# convert_to_cv_image(_last_rgb_msg)\n",
    "#### direct conversion to CV2 ####\n",
    "cv_img = np.frombuffer(_last_depth_msg.data, np.uint16)\n",
    "cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b68388",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "# cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb367cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     rospy.spinOnce()\n",
    "    \n",
    "np_image = convert_to_cv_image(_last_rgb_msg)\n",
    "np_depth_image = convert_to_cv_image(_last_depth_msg)\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = predictor(np_image)\n",
    "finish_time = time.time()\n",
    "print(\"Time to predict:\" + str(finish_time- start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "result = outputs[\"instances\"].to(\"cpu\")\n",
    "finish_time = time.time()\n",
    "print(\"CPU transfer:\" + str(finish_time- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = result.pred_classes if result.has(\"pred_classes\") else None\n",
    "class_names = np.array(_class_names)[class_ids.numpy()]        \n",
    "# arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "retain_inds = (result.scores.numpy() > 0.65) & (class_names == 'person')\n",
    "\n",
    "result = result[retain_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13daf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(result)\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "image_msg = bridge.cv2_to_imgmsg(img)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_depth_img = getStaticDepthImage(np_depth_image, result, _class_names)\n",
    "\n",
    "start_time = time.time()\n",
    "result_msg = getResult(result, _rgb_header, bridge, _class_names)\n",
    "finish_time = time.time()\n",
    "print(\"Results msg time:\" + str(finish_time- start_time))\n",
    "\n",
    "_result_pub.publish(result_msg)\n",
    "\n",
    "# Visualize resultsresult_msg\n",
    "start_time = time.time()\n",
    "v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "image_msg = bridge.cv2_to_imgmsg(img)\n",
    "finish_time = time.time()\n",
    "print(\"Visualisation time:\" + str(finish_time- start_time))\n",
    "\n",
    "plt.imshow(img)\n",
    "# self._vis_pub.publish(image_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get camera info\n",
    "rospy.loginfo(\"Updating camera info\")\n",
    "cameraInfo = rospy.wait_for_message('/camera/color/camera_info', CameraInfo, 60)\n",
    "P = cameraInfo.P\n",
    "image_width = cameraInfo.width\n",
    "image_height = cameraInfo.height\n",
    "\n",
    "intrinsics = rs2.intrinsics()\n",
    "intrinsics.width = cameraInfo.width\n",
    "intrinsics.height = cameraInfo.height\n",
    "intrinsics.ppx = cameraInfo.K[2]\n",
    "intrinsics.ppy = cameraInfo.K[5]\n",
    "intrinsics.fx = cameraInfo.K[0]\n",
    "intrinsics.fy = cameraInfo.K[4]\n",
    "intrinsics.model = rs2.distortion.brown_conrady\n",
    "\n",
    "# Get the pixel location and depth of person centroid\n",
    "depth_img_copy = np_depth_image.copy()\n",
    "masks = np.asarray(result.pred_masks)\n",
    "\n",
    "count = (masks[0] == 1).sum()\n",
    "\n",
    "y_center, x_center = np.argwhere(masks[0]==True).sum(0)/count\n",
    "\n",
    "depth = np.median(depth_img_copy[masks[0].astype(bool)])\n",
    "x_center, y_center, depth\n",
    "\n",
    "# Convert to 3D position in camera coords \n",
    "xyz = rs2.rs2_deproject_pixel_to_point(intrinsics, [x_center, y_center], depth/1000.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ee636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
