{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4382c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import rospy\n",
    "from centermask.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2_ros.msg import Result\n",
    "from sensor_msgs.msg import Image, CompressedImage, RegionOfInterest\n",
    "import matplotlib.pyplot as plt\n",
    "import message_filters\n",
    "import pyrealsense2 as rs2\n",
    "from sensor_msgs.msg import CameraInfo\n",
    "\n",
    "import centermask.modeling.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f0b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2_ros.msg import PersonPositions, PersonPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2b05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(param, default=None):\n",
    "    new_param = rospy.get_param(param, default)\n",
    "    rospy.loginfo(\"[Centermask2] %s: %s\", param, new_param)\n",
    "    return new_param\n",
    "\n",
    "def convert_to_cv_image(image_msg):\n",
    "\n",
    "    if image_msg is None:\n",
    "        return None\n",
    "\n",
    "    channels = int(len(image_msg.data) / (image_msg.width * image_msg.height))\n",
    "\n",
    "    encoding = None\n",
    "    if image_msg.encoding.lower() in ['rgb8', 'bgr8']:\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == 'mono8':\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "    # For depth images        \n",
    "        encoding = np.uint16\n",
    "        channels = 1\n",
    "    elif image_msg.encoding.lower() == '32fc1':\n",
    "        encoding = np.float32\n",
    "        channels = 1\n",
    "\n",
    "    cv_img = np.ndarray(shape=(image_msg.height, image_msg.width, channels),\n",
    "                        dtype=encoding, buffer=image_msg.data)\n",
    "\n",
    "    if image_msg.encoding.lower() == 'mono8':\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "        pass\n",
    "    else:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_img\n",
    "\n",
    "def convert_compressed_to_cv_image(image_msg):\n",
    "\n",
    "    # 'msg' as type CompressedImage\n",
    "    depth_fmt, compr_type = image_msg.format.split(';')\n",
    "    # remove white space\n",
    "    depth_fmt = depth_fmt.strip()\n",
    "    compr_type = compr_type.strip()\n",
    "\n",
    "    if image_msg is None:\n",
    "        return None\n",
    "\n",
    "    encoding = None\n",
    "    if depth_fmt.lower() in ['rgb8', 'bgr8']:\n",
    "        encoding = np.uint8\n",
    "    elif depth_fmt.lower() == 'mono8':\n",
    "        encoding = np.uint8\n",
    "    elif depth_fmt.lower() == '16uc1':\n",
    "    # For depth images        \n",
    "        encoding = np.uint8\n",
    "        channels = 1\n",
    "    elif depth_fmt.lower() == '32fc1':\n",
    "        encoding = np.float32\n",
    "        channels = 1\n",
    "\n",
    "    cv_img = np.frombuffer(image_msg.data, encoding)\n",
    "    \n",
    "    if depth_fmt.lower() == '16uc1':\n",
    "        cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "\n",
    "                             \n",
    "    if depth_fmt.lower() == 'mono8':\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)\n",
    "    elif depth_fmt.lower() == '16uc1':\n",
    "        pass\n",
    "    else:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_img\n",
    "\n",
    "def getStaticDepthImage(depth_image, predictions, class_names):\n",
    "\n",
    "    static_depth_img = depth_image.copy()\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((15,15),np.uint8)\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "#         static_depth_img[masks[inds[i]]]=0\n",
    "        static_depth_img[(cv.dilate(np.float32(masks[inds[i]]),kernel,iterations = 2)).astype(bool)]=0\n",
    "\n",
    "    return static_depth_img\n",
    "\n",
    "def getResult(predictions, header, bridge, class_names):\n",
    "\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    result_msg = Result()\n",
    "    result_msg.header = header\n",
    "    result_msg.class_ids = class_ids[arr]\n",
    "    result_msg.class_names = class_names[arr]\n",
    "    result_msg.scores = scores[arr]\n",
    "\n",
    "#     for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "\n",
    "#     for i in inds:\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "        mask = np.zeros(masks[i].shape, dtype=\"uint8\")\n",
    "        mask[masks[i, :, :]]=255\n",
    "        mask = bridge.cv2_to_imgmsg(mask)\n",
    "        result_msg.masks.append(mask)\n",
    "\n",
    "        box = RegionOfInterest()\n",
    "        box.x_offset = np.uint32(x1)\n",
    "        box.y_offset = np.uint32(y1)\n",
    "        box.height = np.uint32(y2 - y1)\n",
    "        box.width = np.uint32(x2 - x1)\n",
    "        result_msg.boxes.append(box)\n",
    "\n",
    "    return result_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbc82fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1630400681.200587]: [Centermask2] ~detection_threshold: None\n",
      "[INFO] [1630400683.439375]: [Centermask2] ~visualization: True\n"
     ]
    }
   ],
   "source": [
    "rospy.init_node('centermask2_ros')\n",
    "\n",
    "bridge = CvBridge()\n",
    "_last_rgb_msg = None\n",
    "_last_depth_msg = None\n",
    "_msg_lock = threading.Lock()\n",
    "_image_counter = 0\n",
    "\n",
    "cfg = get_cfg()\n",
    "# cfg.merge_from_file(load_param('~config'))\n",
    "# cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_V_99_eSE_FPN_ms_3x.yaml\")\n",
    "cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = load_param('~detection_threshold') # set threshold for this model\n",
    "# cfg.MODEL.WEIGHTS = load_param('~model')\n",
    "# cfg.MODEL.WEIGHTS = \"/root/centermask2-V-99-eSE-FPN-ms-3x.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"/root/centermask2-lite-V-39-eSE-FPN-ms-4x.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "_class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).get(\"thing_classes\", None)\n",
    "\n",
    "_visualization = load_param('~visualization',True)\n",
    "_result_pub = rospy.Publisher('result', Result, queue_size=1)\n",
    "_vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)\n",
    "\n",
    "\n",
    "callback_init = False\n",
    "\n",
    "def callback_images(rgb_msg, depth_msg):\n",
    "    rospy.logdebug(\"Get an image\")\n",
    "    if _msg_lock.acquire(False):\n",
    "        _last_rgb_msg = rgb_msg\n",
    "        _last_depth_msg = depth_msg\n",
    "        _rgb_header = rgb_msg.header\n",
    "        _depth_header = depth_msg.header\n",
    "        _msg_lock.release()\n",
    "    callback_init = True\n",
    "        \n",
    "# _sub = rospy.Subscriber(load_param('~input'), Image, callback_image, queue_size=1)\n",
    "# _image_sub = rospy.Subscriber('/camera/color/image_raw', Image, callback_image, queue_size=1)\n",
    "# _depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw', Image, callback_image, queue_size=1)\n",
    "\n",
    "# _image_sub = message_filters.Subscriber('/camera/color/image_raw', CompressedImage)\n",
    "# _depth_sub = message_filters.Subscriber('/camera/depth/image_rect_raw', CompressedImage)\n",
    "        \n",
    "# ts = message_filters.ApproximateTimeSynchronizer([_image_sub, _depth_sub], 1, 0.003)\n",
    "# ts.registerCallback(callback_images)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "_last_rgb_msg_raw = rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None)\n",
    "_last_depth_msg_raw = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw', Image, timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5dd0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CompressedImage' object has no attribute 'width'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1e48889c883c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_cv_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_last_depth_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6bcc1096accf>\u001b[0m in \u001b[0;36mconvert_to_cv_image\u001b[0;34m(image_msg)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CompressedImage' object has no attribute 'width'"
     ]
    }
   ],
   "source": [
    "plt.imshow(convert_to_cv_image(_last_depth_msg_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd277189",
   "metadata": {},
   "outputs": [],
   "source": [
    "_last_rgb_msg = rospy.wait_for_message('/camera/color/image_raw/compressed', CompressedImage, timeout=None)\n",
    "_last_depth_msg = rospy.wait_for_message('/camera/depth/image_rect_raw/compressed', CompressedImage, timeout=None)\n",
    "# _last_compresseddepth_msg = rospy.wait_for_message('/camera/depth/image_rect_raw/compressedDepth', CompressedImage, timeout=None)\n",
    "# _last_depth_msg = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw/compressed', CompressedImage, timeout=None)\n",
    "_rgb_header = _last_rgb_msg.header\n",
    "_depth_header = _last_depth_msg.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b57bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06669712100000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur = _last_rgb_msg.header.stamp - _last_depth_msg.header.stamp\n",
    "dur.to_sec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562f539b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_last_compresseddepth_msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-60a38034cf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_last_compresseddepth_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_last_compresseddepth_msg' is not defined"
     ]
    }
   ],
   "source": [
    "cv_img = np.frombuffer(_last_compresseddepth_msg.data, np.uint16)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4916822",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_last_compresseddepth_msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96876c8c523f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 'msg' as type CompressedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdepth_fmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompr_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_last_compresseddepth_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# remove white space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdepth_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcompr_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_last_compresseddepth_msg' is not defined"
     ]
    }
   ],
   "source": [
    "# 'msg' as type CompressedImage\n",
    "depth_fmt, compr_type = _last_compresseddepth_msg.format.split(';')\n",
    "# remove white space\n",
    "depth_fmt = depth_fmt.strip()\n",
    "compr_type = compr_type.strip()\n",
    "if compr_type != \"compressedDepth\":\n",
    "    raise Exception(\"Compression type is not 'compressedDepth'.\"\n",
    "                    \"You probably subscribed to the wrong topic.\")\n",
    "\n",
    "# remove header from raw data\n",
    "depth_header_size = 12\n",
    "raw_data = _last_compresseddepth_msg.data[depth_header_size:]\n",
    "\n",
    "depth_img_raw = cv.imdecode(np.frombuffer(raw_data, np.uint8), cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For depth images        \n",
    "encoding = np.uint16\n",
    "channels = 1\n",
    "\n",
    "cv_img = np.frombuffer(_last_depth_msg.data, np.uint8)\n",
    "# cv_img.dtype = np.uint16\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if depth_fmt.lower() == '16uc1':\n",
    "#     cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)\n",
    "# else:\n",
    "#     cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "\n",
    "        \n",
    "cv_img = np.ndarray(shape=(480, 640, channels),\n",
    "                    dtype=encoding, buffer=_last_depth_msg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95711f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_last_depth_msg_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a6b1c5c83fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_cv_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_last_depth_msg_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_img_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_last_depth_msg_raw' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "\n",
    "ax1.imshow(convert_to_cv_image(_last_depth_msg_raw))\n",
    "ax1.set_title(\"Raw\")\n",
    "ax2.imshow(depth_img_raw)\n",
    "ax2.set_title(\"CompressedDepth\")\n",
    "ax3.imshow(convert_compressed_to_cv_image(_last_depth_msg))\n",
    "ax3.set_title(\"Compressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('depth_compression_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835bb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_transport import SubscriberFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ca688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2fe4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(bridge.compressed_imgmsg_to_cv2(_last_depth_msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c78ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bridge.compressed_imgmsg_to_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10212ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = rospy.wait_for_message('/depth', Image, timeout=None)\n",
    "plt.imshow(convert_to_cv_image(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'msg' as type CompressedImage\n",
    "depth_fmt, compr_type = _last_depth_msg.format.split(';')\n",
    "# remove white space\n",
    "depth_fmt = depth_fmt.strip()\n",
    "compr_type = compr_type.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imdecode(_last_rgb_msg, cv.CV_LOAD_IMAGE_UNCHANGED)\n",
    "# convert_to_cv_image(_last_rgb_msg)\n",
    "#### direct conversion to CV2 ####\n",
    "cv_img = np.frombuffer(_last_depth_msg.data, np.uint16)\n",
    "cv_img = cv.imdecode(cv_img, cv.IMREAD_ANYDEPTH)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_COLOR)\n",
    "# cv_img = cv.imdecode(cv_img, cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b68388",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "# cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb367cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     rospy.spinOnce()\n",
    "    \n",
    "np_image = convert_to_cv_image(_last_rgb_msg)\n",
    "np_depth_image = convert_to_cv_image(_last_depth_msg)\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = predictor(np_image)\n",
    "finish_time = time.time()\n",
    "print(\"Time to predict:\" + str(finish_time- start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "result = outputs[\"instances\"].to(\"cpu\")\n",
    "finish_time = time.time()\n",
    "print(\"CPU transfer:\" + str(finish_time- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = result.pred_classes if result.has(\"pred_classes\") else None\n",
    "class_names = np.array(_class_names)[class_ids.numpy()]        \n",
    "# arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "retain_inds = (result.scores.numpy() > 0.65) & (class_names == 'person')\n",
    "\n",
    "result = result[retain_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13daf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(result)\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "image_msg = bridge.cv2_to_imgmsg(img)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_depth_img = getStaticDepthImage(np_depth_image, result, _class_names)\n",
    "\n",
    "start_time = time.time()\n",
    "result_msg = getResult(result, _rgb_header, bridge, _class_names)\n",
    "finish_time = time.time()\n",
    "print(\"Results msg time:\" + str(finish_time- start_time))\n",
    "\n",
    "_result_pub.publish(result_msg)\n",
    "\n",
    "# Visualize resultsresult_msg\n",
    "start_time = time.time()\n",
    "v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "image_msg = bridge.cv2_to_imgmsg(img)\n",
    "finish_time = time.time()\n",
    "print(\"Visualisation time:\" + str(finish_time- start_time))\n",
    "\n",
    "plt.imshow(img)\n",
    "# self._vis_pub.publish(image_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get camera info\n",
    "rospy.loginfo(\"Updating camera info\")\n",
    "cameraInfo = rospy.wait_for_message('/camera/color/camera_info', CameraInfo, 60)\n",
    "P = cameraInfo.P\n",
    "image_width = cameraInfo.width\n",
    "image_height = cameraInfo.height\n",
    "\n",
    "intrinsics = rs2.intrinsics()\n",
    "intrinsics.width = cameraInfo.width\n",
    "intrinsics.height = cameraInfo.height\n",
    "intrinsics.ppx = cameraInfo.K[2]\n",
    "intrinsics.ppy = cameraInfo.K[5]\n",
    "intrinsics.fx = cameraInfo.K[0]\n",
    "intrinsics.fy = cameraInfo.K[4]\n",
    "intrinsics.model = rs2.distortion.brown_conrady\n",
    "\n",
    "# Get the pixel location and depth of person centroid\n",
    "depth_img_copy = np_depth_image.copy()\n",
    "masks = np.asarray(result.pred_masks)\n",
    "\n",
    "count = (masks[0] == 1).sum()\n",
    "\n",
    "y_center, x_center = np.argwhere(masks[0]==True).sum(0)/count\n",
    "\n",
    "depth = np.median(depth_img_copy[masks[0].astype(bool)])\n",
    "x_center, y_center, depth\n",
    "\n",
    "# Convert to 3D position in camera coords \n",
    "xyz = rs2.rs2_deproject_pixel_to_point(intrinsics, [x_center, y_center], depth/1000.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ee636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
