{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4382c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from centermask.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2_ros.msg import Result\n",
    "from sensor_msgs.msg import Image, RegionOfInterest, CameraInfo\n",
    "import pyrealsense2 as rs2\n",
    "\n",
    "# from detectron2_ros.msg import PersonPositions, PersonPosition\n",
    "from finean_msgs.msg import PersonPositions, PersonPosition\n",
    "\n",
    "# For sync depth and rgb\n",
    "import message_filters\n",
    "\n",
    "\n",
    "# Needed to update backbone registry\n",
    "import centermask.modeling.backbone\n",
    "\n",
    "\n",
    "# For the dataset loading\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13d30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_to_rotMat(yaw, pitch, roll):\n",
    "    Rz_yaw = np.array([\n",
    "        [np.cos(yaw), -np.sin(yaw), 0],\n",
    "        [np.sin(yaw),  np.cos(yaw), 0],\n",
    "        [          0,            0, 1]])\n",
    "    Ry_pitch = np.array([\n",
    "        [ np.cos(pitch), 0, np.sin(pitch)],\n",
    "        [             0, 1,             0],\n",
    "        [-np.sin(pitch), 0, np.cos(pitch)]])\n",
    "    Rx_roll = np.array([\n",
    "        [1,            0,             0],\n",
    "        [0, np.cos(roll), -np.sin(roll)],\n",
    "        [0, np.sin(roll),  np.cos(roll)]])\n",
    "    # R = RzRyRx\n",
    "    rotMat = np.dot(Rz_yaw, np.dot(Ry_pitch, Rx_roll))\n",
    "    return rotMat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0161b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box.\n",
    "    # NOTE: We MUST ALWAYS add +1 to calculate area when working in\n",
    "    # screen coordinates, since 0,0 is the top left pixel, and w-1,h-1\n",
    "    # is the bottom right pixel. If we DON'T add +1, the result is wrong.\n",
    "    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1'] + 1) * (bb1['y2'] - bb1['y1'] + 1)\n",
    "    bb2_area = (bb2['x2'] - bb2['x1'] + 1) * (bb2['y2'] - bb2['y1'] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2b05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KTPAnalyser(object):\n",
    "    def __init__(self, depth_offset=100):\n",
    "        print(\"Initializing\")\n",
    "        setup_logger()\n",
    "\n",
    "        self._bridge = CvBridge()\n",
    "        self.score_thresh = 0.50\n",
    "        self.removal_classes = ['person']\n",
    "\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml\")\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 # set threshold for this model\n",
    "        self.cfg.MODEL.WEIGHTS = \"/root/centermask2-lite-V-39-eSE-FPN-ms-4x.pth\"\n",
    "        self.predictor = DefaultPredictor(self.cfg)\n",
    "        self._class_names = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).get(\"thing_classes\", None)\n",
    "        \n",
    "        self.getManualKinectIntrinsics()\n",
    "\n",
    "        self.base_T_rgb = np.eye(4)\n",
    "        self.base_T_rgb[0:3,3] = np.array([-0.27, 1.271, 0.002])\n",
    "        self.base_T_rgb[0:3,0:3] = euler_to_rotMat(-3.142, -0.001, -1.651)\n",
    "        self.base_T_rgb = np.linalg.inv(self.base_T_rgb)\n",
    "        \n",
    "        self.depth_offset = depth_offset\n",
    "        \n",
    "        print(\"Centermask2 Node Initialized\")\n",
    "\n",
    "    def convertPixelToPosition(self, depth_img, mask):\n",
    "        # Get the pixel location and depth of person centroid\n",
    "\n",
    "        mask_positions_2d = np.argwhere(mask==True)\n",
    "        approx_head_thresh = np.quantile(mask_positions_2d[:,0], 0.10)\n",
    "        head_pos_mask = mask_positions_2d[:,0] < approx_head_thresh\n",
    "\n",
    "        count = (head_pos_mask == 1).sum()\n",
    "\n",
    "        y_center, x_center = mask_positions_2d[head_pos_mask, :].sum(0)/count\n",
    "        \n",
    "        y_thresh_mask = (np.argwhere((mask == True) | (mask == False))[:,0] < approx_head_thresh)\n",
    "        y_thresh_mask = y_thresh_mask.reshape((480,640))\n",
    "        \n",
    "        head_mask = mask & y_thresh_mask\n",
    "        \n",
    "#         plt_img = np.zeros(depth_img.shape)\n",
    "#         plt_img[head_mask.astype(bool)] = 1\n",
    "#         plt.imshow(plt_img)\n",
    "#         return\n",
    "#         y_center, x_center = np.argwhere(mask==True).sum(0)/count\n",
    "#         depth = np.median(depth_img[mask.astype(bool)]) + self.depth_offset\n",
    "\n",
    "        non_zero_depth = depth_img[head_mask.astype(bool)]\n",
    "        non_zero_depth = non_zero_depth[non_zero_depth>0]\n",
    "        depth = np.median(non_zero_depth) + analyser.depth_offset\n",
    "#         print(depth)\n",
    "\n",
    "        # Convert to 3D position in camera coords \n",
    "        xyz = rs2.rs2_deproject_pixel_to_point(self.intrinsics, [x_center, y_center], depth/1000.0)\n",
    "        \n",
    "#         print(\"pixel [x,y, depth]\")\n",
    "#         print([x_center, y_center, depth])\n",
    "        # return xyz\n",
    "        return xyz\n",
    "\n",
    "    def getManualKinectIntrinsics(self):\n",
    "        # D: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        # K: [525.0, 0.0, 319.5, 0.0, 525.0, 239.5, 0.0, 0.0, 1.0]\n",
    "        # R: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
    "        # P: [525.0, 0.0, 319.5, 0.0, 0.0, 525.0, 239.5, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
    "\n",
    "\n",
    "        print(\"Updating camera info\")\n",
    "\n",
    "        self.intrinsics = rs2.intrinsics()\n",
    "        self.intrinsics.width = 640\n",
    "        self.intrinsics.height = 480\n",
    "        self.intrinsics.ppx = 319.5\n",
    "        self.intrinsics.ppy = 239.5\n",
    "        self.intrinsics.fx = 525.0\n",
    "        self.intrinsics.fy = 525.0\n",
    "        self.intrinsics.model = rs2.distortion.brown_conrady\n",
    "\n",
    "    def run(self, rgb_file, depth_file, robot_pose):\n",
    "\n",
    "        world_T_base = np.eye(4)\n",
    "        world_T_base[0:3,3] = np.array([robot_pose[0], robot_pose[1], robot_pose[2]])\n",
    "        \n",
    "#         print(robot_pose)\n",
    "        world_T_base[0:3,0:3] = euler_to_rotMat(robot_pose[5], robot_pose[4], robot_pose[3])   \n",
    "         \n",
    "        # Convert images\n",
    "        np_image = cv.imread(rgb_file)\n",
    "        np_depth_image = cv.imread(depth_file, cv.IMREAD_ANYDEPTH)\n",
    "\n",
    "        np_depth_image_copy = np.zeros(np_depth_image.shape)\n",
    "        \n",
    "        # Get the masks and objects seen\n",
    "        outputs = self.predictor(np_image)\n",
    "        result = outputs[\"instances\"].to(\"cpu\")\n",
    "        \n",
    "#         result_msg = self.getResult(result)\n",
    "        \n",
    "        # Mask out people with score greater than threshold\n",
    "        class_ids = result.pred_classes if result.has(\"pred_classes\") else None\n",
    "        class_names = np.array(self._class_names)[class_ids.numpy()]        \n",
    "        retain_inds = (result.scores.numpy() > self.score_thresh) & (class_names == 'person')\n",
    "        result = result[retain_inds]\n",
    "\n",
    "        num_inds = sum(retain_inds)\n",
    "#         print(\"Number of masks: {0}\".format(num_inds))\n",
    "\n",
    "#         boxes = result.pred_boxes if result.has(\"pred_boxes\") else None\n",
    "#         for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "#             continue\n",
    "    \n",
    "        positions_3d_world = []\n",
    "        if num_inds > 0:\n",
    "            masks = np.asarray(result.pred_masks)\n",
    "            for i in range(num_inds):\n",
    "                mask = masks[i]\n",
    "                person_position = self.convertPixelToPosition(np_depth_image, mask)\n",
    "#                 print(person_position)\n",
    "                np_depth_image_copy[mask] = 1\n",
    "                \n",
    "                # Convert to world frame                 \n",
    "                head_T_person = np.eye(4)\n",
    "                head_T_person[0:3,3] = [person_position[0], person_position[1], person_position[2]]\n",
    "                \n",
    "\n",
    "                world_T_head = np.dot(world_T_base, self.base_T_rgb)\n",
    "                world_T_person = np.dot(world_T_head, head_T_person)\n",
    "\n",
    "                world_xyz = world_T_person[0:3,3]\n",
    "#                 print('{0. 2f},{1. 2f},{2. 2f}'.format(world_xyz[0],world_xyz[1],world_xyz[2]))\n",
    "#                 print([\"{0:0.2f}\".format(i) for i in world_xyz])\n",
    "#                 print(\"{0:0.2f}, {1:0.2f}, {2:0.2f}\".format(world_xyz[0], world_xyz[1], world_xyz[2]))\n",
    "                positions_3d_world.append(world_xyz)\n",
    "        \n",
    "#         plt.imshow(np_depth_image_copy)\n",
    "      \n",
    "#         v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "#         v = v.draw_instance_predictions(result)\n",
    "#         img = v.get_image()[:, :, ::-1]\n",
    "#         plt.imshow(img)\n",
    "            \n",
    "#         print(\"Allpositions extracted...\")\n",
    "        return [result, positions_3d_world]\n",
    "    \n",
    "    def getResult(self, predictions):\n",
    "\n",
    "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "        if predictions.has(\"pred_masks\"):\n",
    "            masks = np.asarray(predictions.pred_masks)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        result_msg = Result()\n",
    "        result_msg.class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "        result_msg.class_names = np.array(self._class_names)[result_msg.class_ids.numpy()]\n",
    "        result_msg.scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "\n",
    "        for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "            mask = np.zeros(masks[i].shape, dtype=\"uint8\")\n",
    "            mask[masks[i, :, :]]=255\n",
    "            mask = self._bridge.cv2_to_imgmsg(mask)\n",
    "            result_msg.masks.append(mask)\n",
    "\n",
    "            box = RegionOfInterest()\n",
    "            box.x_offset = np.uint32(x1)\n",
    "            box.y_offset = np.uint32(y1)\n",
    "            box.height = np.uint32(y2 - y1)\n",
    "            box.width = np.uint32(x2 - x1)\n",
    "            result_msg.boxes.append(box)\n",
    "\n",
    "        return result_msg\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def load_param(param, default=None):\n",
    "        new_param = rospy.get_param(param, default)\n",
    "        rospy.loginfo(\"[Centermask2] %s: %s\", param, new_param)\n",
    "        return new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f511f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isMatch(gt_poses, est_pose):\n",
    "    min_dist = 10000\n",
    "    for i in range(len(gt_poses)):\n",
    "        dist = np.sqrt(np.sum(np.square(np.array(gt_poses[i][1:3], dtype=float) - est_pose[0:2])))\n",
    "        min_dist = min(min_dist, dist)\n",
    "    \n",
    "    match = False\n",
    "    if min_dist < 0.3:\n",
    "        match = True\n",
    "        \n",
    "    return [match, min_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8784bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"/root/KTP_Dataset_Text\";\n",
    "image_folder = dataset_folder + \"/images\";\n",
    "ground_truth_folder = dataset_folder + \"/ground_truth\";\n",
    "\n",
    "\n",
    "videos = ['Still', 'Rotation', 'Translation', 'Arc']\n",
    "\n",
    "vid = videos[3]\n",
    "\n",
    "rgb_path = image_folder + \"/\" + vid + \"/rgb\"\n",
    "depth_path = image_folder + \"/\" + vid + \"/depth\"\n",
    "odom_path = ground_truth_folder + \"/\" + vid + \"_robot_pose.txt\"\n",
    "\n",
    "pos3d_path = ground_truth_folder + \"/\" + vid + \"_gt3D.txt\"\n",
    "pos2d_path = ground_truth_folder + \"/\" + vid + \"_gt2D.txt\"\n",
    "\n",
    "rgb_files = [f for f in listdir(rgb_path) if isfile(join(rgb_path, f))]\n",
    "depth_files = [f for f in listdir(depth_path) if isfile(join(depth_path, f))]\n",
    "\n",
    "pose_dict = {}\n",
    "with open(odom_path, 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in reader:\n",
    "        arr = row[0].split(' ')\n",
    "        pose_dict[arr[0].strip(':')] = arr[1:]\n",
    "        \n",
    "gt_3d_dict = {}\n",
    "with open(pos3d_path, 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in reader:\n",
    "        if len(row) > 1:\n",
    "            row = row[0:-1]\n",
    "            t_stamp = row[0].split(' ')[0].strip(':')\n",
    "\n",
    "            markers = []\n",
    "            \n",
    "            for i in range(len(row)):\n",
    "                markers.append(row[i].split(' ')[1:])\n",
    "\n",
    "            gt_3d_dict[t_stamp] = markers\n",
    "            \n",
    "gt_2d_dict = {}\n",
    "with open(pos2d_path, 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in reader:\n",
    "        if len(row) > 1:\n",
    "            row = row[0:-1]\n",
    "            t_stamp = row[0].split(' ')[0].strip(':')\n",
    "\n",
    "            markers = []\n",
    "            \n",
    "            for i in range(len(row)):\n",
    "                markers.append(row[i].split(' ')[1:])\n",
    "\n",
    "            gt_2d_dict[t_stamp] = markers\n",
    "              \n",
    "rgb_timestamps = [img.strip('.jpg') for img in rgb_files]\n",
    "depth_timestamps = [img.strip('.pgm') for img in depth_files]\n",
    "pose_timestamps = list(pose_dict.keys())\n",
    "\n",
    "# Check that all rgb, depth and odom timetsamps match \n",
    "depth_ctr = 0 \n",
    "pose_ctr = 0 \n",
    "for t in rgb_timestamps:\n",
    "    depth_ctr += int(t in depth_timestamps)\n",
    "    pose_ctr += int(t in pose_timestamps)\n",
    "    \n",
    "#     if int(t in depth_timestamps):\n",
    "#         print(t)\n",
    "\n",
    "# assert(depth_ctr == len(rgb_timestamps))\n",
    "# assert(pose_ctr == len(rgb_timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c24149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sorted(list(gt_2d_dict.keys())):\n",
    "#     print(i)\n",
    "\n",
    "# sorted_tstamps = [float(i) for i in list(gt_2d_dict.keys())]\n",
    "# sorted_tstamps = sorted(sorted_tstamps, key=float)\n",
    "# plt.scatter(sorted_tstamps, np.ones(len(sorted_tstamps)))\n",
    "# plt.show()\n",
    "# for i in sorted_tstamps:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b089712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still   \n",
    "timstamp_bounds_dict = {}\n",
    "\n",
    "timstamp_bounds_dict['Still'] = {1:[1339064317.986969085 - 1339064331.038245693],\n",
    "2:[1339064331.768289875, 1339064360.067097068],\n",
    "3:[1339064362.503071436, 1339064366.710322787],\n",
    "4:[1339064369.814646105, 1339064371.979220992],\n",
    "5:[1339064375.185916521, 1339064388.595394236]}\n",
    "\n",
    "# Rotation\n",
    "timstamp_bounds_dict['Rotation'] = {1:[1339072026.143797066, 1339072036.622872171],\n",
    "2:[1339072038.992151379, 1339072070.026229981],\n",
    "3:[1339072070.060515464, 1339072074.762523787],\n",
    "4:[1339072078.269397000, 1339072080.104408822],\n",
    "5:[1339072083.473387965, 1339072097.586308065]}\n",
    "\n",
    "# Translation\n",
    "timstamp_bounds_dict['Translation'] = {1:[1339066241.703633641, 1339066253.713979618],\n",
    "2:[1339066255.481776113, 1339066282.147084186],\n",
    "3:[1339066282.215393574, 1339066286.951295705],\n",
    "4:[1339066289.056906724, 1339066291.324039606],\n",
    "5:[1339066294.858379375, 1339066308.207410858]}\n",
    "\n",
    "# Arc\n",
    "timstamp_bounds_dict['Arc'] = {1:[1339072455.526836838, 1339072466.069116626],\n",
    "2:[1339072472.977563961, 1339072494.467989678],\n",
    "3:[1339072496.437215469, 1339072501.409138958],\n",
    "4:[1339072504.309639787, 1339072506.784084572],\n",
    "5:[1339072510.552881349, 1339072524.867087399]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f74b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for offset in [125]:\n",
    "# for offset in [0, 50, 75, 100, 125, 150]:\n",
    "    analyser = KTPAnalyser(depth_offset=offset)\n",
    "    total_possible_3d_matches = 0\n",
    "    total_possible_2d_matches = 0\n",
    "    num_3d_matches = 0\n",
    "    num_2d_matches = 0\n",
    "    min_dist_errors = []\n",
    "    # t_stamps_with_3d_gt = \n",
    "    num_extra = 0 \n",
    "    num_missed = 0\n",
    "    num_3d_not_matches = 0\n",
    "    # for test_t_stamp in list(gt_3d_dict.keys()):\n",
    "#     for test_t_stamp in ['1339064321.890846829']:\n",
    "    for test_t_stamp in tqdm(list(gt_3d_dict.keys())):\n",
    "\n",
    "        try:\n",
    "            rgb_file = rgb_path + \"/\" + str(test_t_stamp) + '.jpg'\n",
    "            depth_file = depth_path + \"/\" + str(test_t_stamp) + '.pgm'\n",
    "            odom_pose = [float(i) for i in pose_dict[test_t_stamp]]\n",
    "            gt_3d_poses = gt_3d_dict[test_t_stamp]\n",
    "            gt_2d_poses = gt_2d_dict[test_t_stamp]\n",
    "\n",
    "\n",
    "            #  Run\n",
    "            [result, poses] = analyser.run(rgb_file, depth_file, odom_pose)\n",
    "\n",
    "            total_possible_3d_matches += len(gt_3d_poses)\n",
    "            total_possible_2d_matches += len(gt_2d_poses)\n",
    "\n",
    "            # 3D position checking         \n",
    "            for pose in poses:\n",
    "                [match, min_dist] = isMatch(gt_3d_poses, pose)\n",
    "                num_3d_matches += int(match)\n",
    "                num_3d_not_matches += int(not(match))\n",
    "    #             if not(match):\n",
    "    #                 print([test_t_stamp, min_dist])\n",
    "                min_dist_errors.append([match, min_dist])\n",
    "\n",
    "            if len(poses) > len(gt_3d_poses):\n",
    "                num_extra += len(poses) - len(gt_3d_poses)\n",
    "\n",
    "            if len(gt_3d_poses) > len(poses):\n",
    "                num_missed += len(gt_3d_poses) - len(poses)\n",
    "\n",
    "            # 2D bbox checking\n",
    "            boxes = result.pred_boxes if result.has(\"pred_boxes\") else None\n",
    "            img_matches = 0\n",
    "            for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "\n",
    "                        bb1 = {'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2}\n",
    "                        max_iou = 0\n",
    "                        for inst in gt_2d_poses:\n",
    "                            gt_bb = {'x1': int(inst[1]), \n",
    "                                     'x2': int(inst[1]) + int(inst[3]), \n",
    "                                     'y1': int(inst[2]), \n",
    "                                     'y2': int(inst[2]) + int(inst[4])}\n",
    "\n",
    "                            iou = get_iou(bb1, gt_bb)\n",
    "                            max_iou = max(max_iou, iou)\n",
    "\n",
    "                        img_matches += int(max_iou >= 0.5)\n",
    "            num_2d_matches += max(img_matches, len(gt_3d_poses))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    min_dist_errors = np.array(min_dist_errors)\n",
    "\n",
    "#     np.array\n",
    "#     # The mean error for associated positions         \n",
    "    mean_assoc_dist_error = np.mean(min_dist_errors[min_dist_errors[:, 0] == 1, 1])\n",
    "        \n",
    "    print(\"Offset {0} \\t  \\\n",
    "          Num 3d matches:{1} \\t Num 2d matches:{2} \\t \\\n",
    "          2d rate:{3} \\t 3d rate: {4} \\t \\\n",
    "          mean_error(m): {5} \\t \\\n",
    "          fn: {6} \\t fp: {7}\".format(offset, \n",
    "                                              num_3d_matches, \n",
    "                                              num_2d_matches, \n",
    "                                              (num_2d_matches-num_extra-num_missed)/total_possible_2d_matches,\n",
    "                                             (num_3d_matches-num_extra-num_missed)/total_possible_3d_matches,\n",
    "                                              mean_assoc_dist_error,\n",
    "                                            num_missed/total_possible_2d_matches,\n",
    "                                             num_extra/total_possible_2d_matches\n",
    "                                                ))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e13e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_errors[:,1]== 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tstamps = min_dist_errors[np.argwhere(min_dist_errors[:,1]== 'False'), 0]\n",
    "print(bad_tstamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c40ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t_stamp = list(gt_3d_dict.keys())[47]\n",
    "test_t_stamp = '1339064385.192367663'\n",
    "\n",
    "rgb_file = still_rgb_path + \"/\" + str(test_t_stamp) + '.jpg'\n",
    "depth_file = still_depth_path + \"/\" + str(test_t_stamp) + '.pgm'\n",
    "odom_pose = [float(i) for i in pose_dict[test_t_stamp]]\n",
    "gt_3d_poses = gt_3d_dict[test_t_stamp]\n",
    "gt_2d_poses = gt_2d_dict[test_t_stamp]\n",
    "rgb_image = cv.imread(rgb_file)\n",
    "np_depth_image = cv.imread(depth_file, cv.IMREAD_ANYDEPTH)\n",
    "\n",
    "#  Run\n",
    "[result, poses] = analyser.run(rgb_file, depth_file, odom_pose)\n",
    "\n",
    "plt.imshow(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(rgb_image[:, :, ::-1], MetadataCatalog.get(analyser.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(result)\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b226a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "isMatch(gt_3d_poses, poses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae301ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05509f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_3d_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.asarray(result.pred_masks)\n",
    "mask = masks[1]\n",
    "person_position = analyser.convertPixelToPosition(np_depth_image, mask)\n",
    "print(person_position)\n",
    "\n",
    "mask_positions_2d = np.argwhere(mask==True)\n",
    "approx_head_thresh = np.quantile(mask_positions_2d[:,0], 0.10)\n",
    "head_pos_mask = mask_positions_2d[:,0] < approx_head_thresh\n",
    "\n",
    "count = (head_pos_mask == 1).sum()\n",
    "\n",
    "y_center, x_center = mask_positions_2d[head_pos_mask, :].sum(0)/count\n",
    "\n",
    "y_thresh_mask = (np.argwhere((mask == True) | (mask == False))[:,0] < approx_head_thresh)\n",
    "y_thresh_mask = y_thresh_mask.reshape((480,640))\n",
    "\n",
    "head_mask = mask & y_thresh_mask\n",
    "\n",
    "plt_img = np.zeros(np_depth_image.shape)\n",
    "plt_img[head_mask.astype(bool)] = 1\n",
    "plt.imshow(plt_img)\n",
    "#         return\n",
    "#         y_center, x_center = np.argwhere(mask==True).sum(0)/count\n",
    "#         depth = np.median(depth_img[mask.astype(bool)]) + self.depth_offset\n",
    " \n",
    "non_zero_depth = np_depth_image[head_mask.astype(bool)]\n",
    "non_zero_depth = non_zero_depth[non_zero_depth>0]\n",
    "depth = np.median(non_zero_depth) + analyser.depth_offset\n",
    "#         print(depth)\n",
    "\n",
    "\n",
    "# np_depth_image_copy[mask] = 1\n",
    "\n",
    "# # Convert to world frame                 \n",
    "# head_T_person = np.eye(4)\n",
    "# head_T_person[0:3,3] = [person_position[0], person_position[1], person_position[2]]\n",
    "\n",
    "\n",
    "# world_T_head = np.dot(world_T_base, self.base_T_rgb)\n",
    "# world_T_person = np.dot(world_T_head, head_T_person)\n",
    "\n",
    "# world_xyz = world_T_person[0:3,3]\n",
    "\n",
    "# positions_3d_world.append(world_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e05b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_center, x_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cfdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth_image[142, 301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88917474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np_depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth_image[head_mask.astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth_image[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b818d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
