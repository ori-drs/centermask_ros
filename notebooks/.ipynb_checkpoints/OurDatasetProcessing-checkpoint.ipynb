{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4382c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from centermask.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2_ros.msg import Result\n",
    "from sensor_msgs.msg import Image, RegionOfInterest, CameraInfo\n",
    "import pyrealsense2 as rs2\n",
    "\n",
    "# from detectron2_ros.msg import PersonPositions, PersonPosition\n",
    "from finean_msgs.msg import PersonPositions, PersonPosition\n",
    "\n",
    "# For sync depth and rgb\n",
    "import message_filters\n",
    "\n",
    "\n",
    "# Needed to update backbone registry\n",
    "import centermask.modeling.backbone\n",
    "\n",
    "\n",
    "# For the dataset loading\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2b05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAnalyser(object):\n",
    "    def __init__(self, depth_offset=100, camera_type='hsr'):\n",
    "        print(\"Initializing\")\n",
    "        setup_logger()\n",
    "\n",
    "        self._bridge = CvBridge()\n",
    "        self.score_thresh = 0.50\n",
    "        self.removal_classes = ['person']\n",
    "        self.camera_type = camera_type\n",
    "        \n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml\")\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 # set threshold for this model\n",
    "        self.cfg.MODEL.WEIGHTS = \"/root/centermask2-lite-V-39-eSE-FPN-ms-4x.pth\"\n",
    "        self.predictor = DefaultPredictor(self.cfg)\n",
    "        self._class_names = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).get(\"thing_classes\", None)\n",
    "\n",
    "        if camera_type == 'hsr':\n",
    "            self.getManualHSRIntrinsics()\n",
    "        elif camera_type == 'realsense':\n",
    "            self.getManualRealsenseIntrinsics()\n",
    "        else:\n",
    "            print(\"Please specify a valid camera type.\")\n",
    "            return\n",
    "            \n",
    "        self.depth_offset = depth_offset\n",
    "        \n",
    "        print(\"Centermask2 Node Initialized\")\n",
    "\n",
    "    def convertPixelToPosition(self, depth_img, mask):\n",
    "        # Get the pixel location and depth of person centroid\n",
    "\n",
    "#         mask_positions_2d = np.argwhere(mask==True)\n",
    "# #         print(\"2d mask\")\n",
    "# #         print(mask_positions_2d)\n",
    "#         approx_head_thresh = np.quantile(mask_positions_2d[:,0], 1.0)\n",
    "# #         print(\"approx_head_thresh\")\n",
    "# #         print(approx_head_thresh)\n",
    "#         head_pos_mask = mask_positions_2d[:,0] < approx_head_thresh\n",
    "# #         print(\"head_pos_mask\")\n",
    "# #         print(head_pos_mask)\n",
    "        \n",
    "#         count = (head_pos_mask == 1).sum()\n",
    "\n",
    "#         y_center, x_center = mask_positions_2d[head_pos_mask, :].sum(0)/count\n",
    "        \n",
    "#         y_thresh_mask = (np.argwhere((mask == True) | (mask == False))[:,0] < approx_head_thresh)\n",
    "#         y_thresh_mask = y_thresh_mask.reshape((480,640))\n",
    "        \n",
    "#         head_mask = mask & y_thresh_mask\n",
    "\n",
    "        mask_positions_2d = np.argwhere(mask==True)\n",
    "        \n",
    "#         print(np.median(mask_positions_2d))\n",
    "        y_center, x_center = np.mean(mask_positions_2d, axis=0)\n",
    "        \n",
    "        head_mask = mask\n",
    "        \n",
    "        \n",
    "        non_zero_depth = depth_img[head_mask.astype(bool)]\n",
    "        non_zero_depth = non_zero_depth[non_zero_depth>0]\n",
    "        depth = np.median(non_zero_depth) + self.depth_offset\n",
    "\n",
    "        # Convert to 3D position in camera coords \n",
    "        xyz = rs2.rs2_deproject_pixel_to_point(self.intrinsics, [x_center, y_center], depth/1000.0)\n",
    "        \n",
    "        return xyz\n",
    "    \n",
    "    def getManualHSRIntrinsics(self):\n",
    "        self.intrinsics = rs2.intrinsics()\n",
    "        self.intrinsics.width = 640\n",
    "        self.intrinsics.height = 480\n",
    "        self.intrinsics.ppx = 322.2156457958147\n",
    "        self.intrinsics.ppy = 238.8396597454201\n",
    "        self.intrinsics.fx = 537.3372465571922\n",
    "        self.intrinsics.fy = 537.8279138435478\n",
    "        self.intrinsics.model = rs2.distortion.brown_conrady\n",
    "\n",
    "    def getManualRealsenseIntrinsics(self):\n",
    "        \n",
    "        self.intrinsics = rs2.intrinsics()\n",
    "        self.intrinsics.width = 640\n",
    "        self.intrinsics.height = 480\n",
    "        self.intrinsics.ppx = 324.9241638183594\n",
    "        self.intrinsics.ppy = 236.38864135742188\n",
    "        self.intrinsics.fx = 618.6040649414062\n",
    "        self.intrinsics.fy = 618.9261474609375\n",
    "        self.intrinsics.model = rs2.distortion.brown_conrady\n",
    "\n",
    "    def run(self, rgb_file, depth_file, camera_frame_transform):\n",
    "\n",
    "        # Convert images\n",
    "        np_image = cv.imread(rgb_file)\n",
    "        np_depth_image = cv.imread(depth_file, cv.IMREAD_ANYDEPTH)\n",
    "\n",
    "        np_depth_image_copy = np.zeros(np_depth_image.shape)\n",
    "        \n",
    "        # Get the masks and objects seen\n",
    "        outputs = self.predictor(np_image)\n",
    "        result = outputs[\"instances\"].to(\"cpu\")\n",
    "        \n",
    "#         result_msg = self.getResult(result)\n",
    "        \n",
    "        # Mask out people with score greater than threshold\n",
    "        class_ids = result.pred_classes if result.has(\"pred_classes\") else None\n",
    "        class_names = np.array(self._class_names)[class_ids.numpy()]        \n",
    "        retain_inds = (result.scores.numpy() > self.score_thresh) & (class_names == 'person')\n",
    "        result = result[retain_inds]\n",
    "\n",
    "        num_inds = sum(retain_inds)\n",
    "#         print(\"Number of masks: {0}\".format(num_inds))\n",
    "\n",
    "#         boxes = result.pred_boxes if result.has(\"pred_boxes\") else None\n",
    "#         for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "#             continue\n",
    "    \n",
    "        positions_3d_world = []\n",
    "        if num_inds > 0:\n",
    "            masks = np.asarray(result.pred_masks)\n",
    "            for i in range(num_inds):\n",
    "                mask = masks[i]\n",
    "#                 print(result)\n",
    "            \n",
    "                if sum(sum(mask == True)) <=10:\n",
    "                    continue\n",
    "            \n",
    "#                 print(\"Lenght of mask: \" + str(len(mask)))\n",
    "                person_position = self.convertPixelToPosition(np_depth_image, mask)\n",
    "#                 print(person_position)\n",
    "                np_depth_image_copy[mask] = 1\n",
    "                \n",
    "                # Convert to world frame                 \n",
    "                head_T_person = np.eye(4)\n",
    "                head_T_person[0:3,3] = [person_position[0], person_position[1], person_position[2]]\n",
    "                \n",
    "                world_T_person = np.dot(camera_frame_transform, head_T_person)\n",
    "\n",
    "#                 print(\"head_T_person\")\n",
    "#                 print(head_T_person)\n",
    "                world_xyz = world_T_person[0:3,3]\n",
    "\n",
    "#                 print(world_xyz)\n",
    "                positions_3d_world += list(world_xyz)\n",
    "        \n",
    "#         plt.imshow(np_depth_image_copy)\n",
    "      \n",
    "#         v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "#         v = v.draw_instance_predictions(result)\n",
    "#         img = v.get_image()[:, :, ::-1]\n",
    "#         plt.imshow(img)\n",
    "            \n",
    "#         print(\"Allpositions extracted...\")\n",
    "        return positions_3d_world\n",
    "    \n",
    "    def getResult(self, predictions):\n",
    "\n",
    "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "        if predictions.has(\"pred_masks\"):\n",
    "            masks = np.asarray(predictions.pred_masks)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        result_msg = Result()\n",
    "        result_msg.class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "        result_msg.class_names = np.array(self._class_names)[result_msg.class_ids.numpy()]\n",
    "        result_msg.scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "\n",
    "        for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "            mask = np.zeros(masks[i].shape, dtype=\"uint8\")\n",
    "            mask[masks[i, :, :]]=255\n",
    "            mask = self._bridge.cv2_to_imgmsg(mask)\n",
    "            result_msg.masks.append(mask)\n",
    "\n",
    "            box = RegionOfInterest()\n",
    "            box.x_offset = np.uint32(x1)\n",
    "            box.y_offset = np.uint32(y1)\n",
    "            box.height = np.uint32(y2 - y1)\n",
    "            box.width = np.uint32(x2 - x1)\n",
    "            result_msg.boxes.append(box)\n",
    "\n",
    "        return result_msg\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def load_param(param, default=None):\n",
    "        new_param = rospy.get_param(param, default)\n",
    "        rospy.loginfo(\"[Centermask2] %s: %s\", param, new_param)\n",
    "        return new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784bdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "from glob import glob\n",
    "\n",
    "dataset_folder = \"/root/HumanTrajectoryPredictionDataset\"\n",
    "\n",
    "camera_transform_dir = dataset_folder + \"/formatted\"\n",
    "\n",
    "output_positions_dir = dataset_folder + \"/estimated_positions\"\n",
    "\n",
    "hsr_analyser = DatasetAnalyser(depth_offset=125, camera_type='hsr')\n",
    "realsense_analyser = DatasetAnalyser(depth_offset=125, camera_type='realsense')\n",
    "\n",
    "for map_num in [1,2,3,4]:\n",
    "    for run in [1,2,3]:\n",
    "# for map_num in [1]:\n",
    "#     for run in [1]:\n",
    "        hsr_rgb_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "        hsr_depth_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/depth\".format(map_num, run)\n",
    "        realsense_rgb_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "        realsense_depth_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/depth\".format(map_num, run)\n",
    "\n",
    "        hsr_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_hsr.csv\".format(map_num, run)\n",
    "        realsense_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_realsense.csv\".format(map_num, run)\n",
    "        \n",
    "        hsr_reader = csv.reader(open(hsr_camera_transform_file), delimiter=\",\")\n",
    "        realsense_reader = csv.reader(open(realsense_camera_transform_file), delimiter=\",\")\n",
    "        \n",
    "        hsr_transform_list = list(hsr_reader)\n",
    "        realsense_transform_list = list(realsense_reader)\n",
    "        \n",
    "        hsr_position_results = []\n",
    "        \n",
    "        hsr_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(hsr_depth_image_folder + '/*.png')]\n",
    "        hsr_depth_tstamps_floats = np.array([float(i) for i in hsr_depth_tstamps])\n",
    "\n",
    "        realsense_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(realsense_depth_image_folder + '/*.png')]\n",
    "        realsense_depth_tstamps_floats = np.array([float(i) for i in realsense_depth_tstamps])\n",
    "        \n",
    "        for row in tqdm(hsr_transform_list):\n",
    "            t_stamp = row[0]\n",
    "            \n",
    "            depth_t_str = hsr_depth_tstamps[np.argmin(abs(hsr_depth_tstamps_floats - float(t_stamp)))]\n",
    "            \n",
    "            rgb_file = hsr_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "            depth_file = hsr_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "            hsr_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "            hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                               depth_file, \n",
    "                                               hsr_camera_transform)\n",
    "        \n",
    "            hsr_position_results.append([t_stamp] + hsr_human_poses)\n",
    "\n",
    "        with open(output_positions_dir + '/map{0}_run{1}_hsr.csv'.format(map_num, run), 'w') as myhsrfile:\n",
    "            hsr_wr = csv.writer(myhsrfile, quoting=csv.QUOTE_ALL)\n",
    "            for i in range(len(hsr_position_results)):\n",
    "                hsr_wr.writerow(hsr_position_results[i])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        realsense_position_results = []\n",
    "        for row in tqdm(realsense_transform_list):\n",
    "\n",
    "            t_stamp = row[0]\n",
    "\n",
    "            depth_t_str = realsense_depth_tstamps[np.argmin(abs(realsense_depth_tstamps_floats - float(t_stamp)))]\n",
    "\n",
    "            rgb_file = realsense_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "            depth_file = realsense_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "            \n",
    "            realsense_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "            realsense_human_poses = realsense_analyser.run(rgb_file, \n",
    "                                               depth_file, \n",
    "                                               realsense_camera_transform)\n",
    "            \n",
    "            realsense_position_results.append([t_stamp] + realsense_human_poses)\n",
    "            \n",
    "\n",
    "        with open(output_positions_dir + '/map{0}_run{1}_realsense.csv'.format(map_num, run), 'w') as myrealsensefile:\n",
    "            realsense_wr = csv.writer(myrealsensefile, quoting=csv.QUOTE_ALL)\n",
    "            for i in range(len(realsense_position_results)):\n",
    "                realsense_wr.writerow(realsense_position_results[i])\n",
    "    \n",
    "        \n",
    "        print(\"Finished mapnum:{0} \\t run:{1}\".format(map_num, run))\n",
    "# result = numpy.array(x).astype(\"float\")\n",
    "\n",
    "#         for t_stamp in \n",
    "#         [hsr_result, hsr_poses] = hsr_analyser.run(rgb_file, depth_file, hsr_camera_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_analyser = DatasetAnalyser(depth_offset=125, camera_type='hsr')\n",
    "hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                   depth_file, \n",
    "                                   hsr_camera_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "realsense_depth_image_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8884623",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_positions_dir + '/map{0}_run{1}_hsr.csv'.format(map_num, run), 'w') as myhsrfile:\n",
    "    hsr_wr = csv.writer(myhsrfile, quoting=csv.QUOTE_ALL)\n",
    "    for i in range(len(hsr_position_results)):\n",
    "        hsr_wr.writerow(hsr_position_results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfa653",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_transform_list[0]\n",
    "np.array(hsr_transform_list[0][1::]).astype(float).reshape((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d05b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_transform_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed43130",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_analyser = DatasetAnalyser(depth_offset=125)\n",
    "        \n",
    "row = hsr_transform_list[0]\n",
    "t_stamp = row[0]\n",
    "\n",
    "depth_t_str = depth_tstamps[np.argmin(depth_tstamps_floats - float(t_stamp))]\n",
    "\n",
    "rgb_file = hsr_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "depth_file = hsr_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "hsr_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                   depth_file, \n",
    "                                   hsr_camera_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56128ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.imread(rgb_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5295e78",
   "metadata": {},
   "source": [
    "# isolated testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "from glob import glob\n",
    "\n",
    "dataset_folder = \"/root/HumanTrajectoryPredictionDataset\"\n",
    "\n",
    "camera_transform_dir = dataset_folder + \"/formatted\"\n",
    "\n",
    "output_positions_dir = dataset_folder + \"/estimated_positions\"\n",
    "\n",
    "hsr_analyser = DatasetAnalyser(depth_offset=125, camera_type='hsr')\n",
    "realsense_analyser = DatasetAnalyser(depth_offset=125, camera_type='realsense')\n",
    "\n",
    "\n",
    "map_num = 1\n",
    "run = 1\n",
    "\n",
    "hsr_rgb_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "hsr_depth_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/depth\".format(map_num, run)\n",
    "realsense_rgb_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "realsense_depth_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/depth\".format(map_num, run)\n",
    "\n",
    "hsr_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_hsr.csv\".format(map_num, run)\n",
    "realsense_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_realsense.csv\".format(map_num, run)\n",
    "\n",
    "hsr_reader = csv.reader(open(hsr_camera_transform_file), delimiter=\",\")\n",
    "realsense_reader = csv.reader(open(realsense_camera_transform_file), delimiter=\",\")\n",
    "\n",
    "hsr_transform_list = list(hsr_reader)\n",
    "realsense_transform_list = list(realsense_reader)\n",
    "\n",
    "hsr_position_results = []\n",
    "\n",
    "hsr_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(hsr_depth_image_folder + '/*.png')]\n",
    "hsr_depth_tstamps_floats = np.array([float(i) for i in hsr_depth_tstamps])\n",
    "\n",
    "realsense_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(realsense_depth_image_folder + '/*.png')]\n",
    "realsense_depth_tstamps_floats = np.array([float(i) for i in realsense_depth_tstamps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec31e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(hsr_transform_list[0:250]):\n",
    "    t_stamp = row[0]\n",
    "\n",
    "    depth_t_str = hsr_depth_tstamps[np.argmin(hsr_depth_tstamps_floats - float(t_stamp))]\n",
    "\n",
    "    rgb_file = hsr_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "    depth_file = hsr_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "    hsr_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "    hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                       depth_file, \n",
    "                                       hsr_camera_transform)\n",
    "\n",
    "    hsr_position_results.append([t_stamp] + hsr_human_poses)\n",
    "\n",
    "# with open(output_positions_dir + '/map{0}_run{1}_hsr.csv'.format(map_num, run), 'w') as myhsrfile:\n",
    "#     hsr_wr = csv.writer(myhsrfile, quoting=csv.QUOTE_ALL)\n",
    "#     for i in range(len(hsr_position_results)):\n",
    "#         hsr_wr.writerow(hsr_position_results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_analyser = DatasetAnalyser(depth_offset=100, camera_type='hsr')\n",
    "\n",
    "row = hsr_transform_list[312]\n",
    "t_stamp = row[0]\n",
    "\n",
    "depth_t_str = hsr_depth_tstamps[np.argmin(abs(hsr_depth_tstamps_floats - float(t_stamp)))]\n",
    "\n",
    "rgb_file = hsr_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "depth_file = hsr_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "hsr_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                   depth_file, \n",
    "                                   hsr_camera_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d402c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsr_human_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c58d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.imread(rgb_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(depth_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "realsense_analyser = DatasetAnalyser(depth_offset=125, camera_type='realsense')\n",
    "row = realsense_transform_list[327]\n",
    "t_stamp = row[0]\n",
    "\n",
    "depth_t_str = realsense_depth_tstamps[np.argmin(abs(realsense_depth_tstamps_floats - float(t_stamp)))]\n",
    "\n",
    "rgb_file = realsense_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "depth_file = realsense_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "realsense_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "realsense_human_poses = realsense_analyser.run(rgb_file, \n",
    "                                   depth_file, \n",
    "                                   realsense_camera_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915880be",
   "metadata": {},
   "outputs": [],
   "source": [
    "realsense_human_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ba30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-1.7424; 0.54158; 1.859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(result.pred_masks).astype(float)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_depth = non_zero_depth[non_zero_depth>0]\n",
    "\n",
    "np.median(np_depth_image[np.asarray(result.pred_masks)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth_image = cv.imread(depth_file, cv.IMREAD_ANYDEPTH)\n",
    "plt.imshow(np_depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth_image[100,590]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f958a",
   "metadata": {},
   "source": [
    "# Offset testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a8074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def checkMakeDir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f28078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 10:32:10 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 10:32:14 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 591/9442 [00:39<09:52, 14.95it/s]/root/.virtualenvs/centermask2/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/root/.virtualenvs/centermask2/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 9442/9442 [10:31<00:00, 14.94it/s]\n",
      "100%|██████████| 9483/9483 [10:25<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 10:53:12 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 10:53:12 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:25<00:00, 15.08it/s]\n",
      "100%|██████████| 9483/9483 [10:22<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:14:01 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:14:01 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:25<00:00, 15.10it/s]\n",
      "100%|██████████| 9483/9483 [10:27<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:34:54 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:34:55 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:29<00:00, 15.00it/s]\n",
      "100%|██████████| 9483/9483 [10:31<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:55:56 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 11:55:56 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:29<00:00, 15.00it/s]\n",
      "100%|██████████| 9483/9483 [10:18<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:16:44 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:16:45 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:29<00:00, 15.01it/s]\n",
      "100%|██████████| 9483/9483 [10:18<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:37:33 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:37:33 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:28<00:00, 15.03it/s]\n",
      "100%|██████████| 9483/9483 [10:25<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:58:27 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 12:58:28 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:34<00:00, 14.87it/s]\n",
      "100%|██████████| 9483/9483 [10:21<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 13:19:24 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 13:19:25 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:21<00:00, 15.20it/s]\n",
      "100%|██████████| 9483/9483 [10:26<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 13:40:13 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 13:40:14 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:30<00:00, 14.98it/s]\n",
      "100%|██████████| 9483/9483 [10:30<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 14:01:15 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n",
      "Initializing\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/31 14:01:16 d2.config.compat]: \u001b[0mConfig '/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Centermask2 Node Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9442/9442 [10:27<00:00, 15.05it/s]\n",
      "100%|██████████| 9483/9483 [10:29<00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mapnum:1 \t run:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy\n",
    "from glob import glob\n",
    "\n",
    "dataset_folder = \"/root/HumanTrajectoryPredictionDataset\"\n",
    "\n",
    "camera_transform_dir = dataset_folder + \"/formatted\"\n",
    "\n",
    "# output_positions_dir = dataset_folder + \"/estimated_positions\"\n",
    "# checkMakeDir(output_positions_dir)\n",
    "\n",
    "# for depth_offset in [0, 50, 100, 150, 200, 250, 300]:\n",
    "for depth_offset in [150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250]:\n",
    "    hsr_analyser = DatasetAnalyser(depth_offset=depth_offset, camera_type='hsr')\n",
    "    realsense_analyser = DatasetAnalyser(depth_offset=depth_offset, camera_type='realsense')\n",
    "#     output_positions_dir = dataset_folder + \"/estimated_positions/offset_{0}\".format(depth_offset) \n",
    "    output_positions_dir = dataset_folder + \"/finetuned_positions/offset_{0}\".format(depth_offset) \n",
    "    checkMakeDir(output_positions_dir)\n",
    "    \n",
    "#     for map_num in [1,2,3,4]:\n",
    "#         for run in [1,2,3]:\n",
    "    for map_num in [1]:\n",
    "        for run in [1]:\n",
    "            hsr_rgb_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "            hsr_depth_image_folder = dataset_folder + \"/images/hsr/map{0}_run{1}/depth\".format(map_num, run)\n",
    "            realsense_rgb_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/rgb\".format(map_num, run)\n",
    "            realsense_depth_image_folder = dataset_folder + \"/images/realsense/map{0}_run{1}/depth\".format(map_num, run)\n",
    "\n",
    "            hsr_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_hsr.csv\".format(map_num, run)\n",
    "            realsense_camera_transform_file = camera_transform_dir + \"/map{0}_run{1}_realsense.csv\".format(map_num, run)\n",
    "\n",
    "            hsr_reader = csv.reader(open(hsr_camera_transform_file), delimiter=\",\")\n",
    "            realsense_reader = csv.reader(open(realsense_camera_transform_file), delimiter=\",\")\n",
    "\n",
    "            hsr_transform_list = list(hsr_reader)\n",
    "            realsense_transform_list = list(realsense_reader)\n",
    "\n",
    "            hsr_position_results = []\n",
    "\n",
    "            hsr_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(hsr_depth_image_folder + '/*.png')]\n",
    "            hsr_depth_tstamps_floats = np.array([float(i) for i in hsr_depth_tstamps])\n",
    "\n",
    "            realsense_depth_tstamps = [row.split('/')[-1].strip('.png') for row in glob(realsense_depth_image_folder + '/*.png')]\n",
    "            realsense_depth_tstamps_floats = np.array([float(i) for i in realsense_depth_tstamps])\n",
    "\n",
    "            for row in tqdm(hsr_transform_list):\n",
    "                t_stamp = row[0]\n",
    "\n",
    "                depth_t_str = hsr_depth_tstamps[np.argmin(abs(hsr_depth_tstamps_floats - float(t_stamp)))]\n",
    "\n",
    "                rgb_file = hsr_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "                depth_file = hsr_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "                hsr_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "                hsr_human_poses = hsr_analyser.run(rgb_file, \n",
    "                                                   depth_file, \n",
    "                                                   hsr_camera_transform)\n",
    "\n",
    "                hsr_position_results.append([t_stamp] + hsr_human_poses)\n",
    "\n",
    "            with open(output_positions_dir + '/map{0}_run{1}_hsr.csv'.format(map_num, run), 'w') as myhsrfile:\n",
    "                hsr_wr = csv.writer(myhsrfile, quoting=csv.QUOTE_ALL)\n",
    "                for i in range(len(hsr_position_results)):\n",
    "                    hsr_wr.writerow(hsr_position_results[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            realsense_position_results = []\n",
    "            for row in tqdm(realsense_transform_list):\n",
    "\n",
    "                t_stamp = row[0]\n",
    "\n",
    "                depth_t_str = realsense_depth_tstamps[np.argmin(abs(realsense_depth_tstamps_floats - float(t_stamp)))]\n",
    "\n",
    "                rgb_file = realsense_rgb_image_folder + \"/{0}.jpg\".format(t_stamp)\n",
    "                depth_file = realsense_depth_image_folder + \"/{0}.png\".format(depth_t_str)\n",
    "\n",
    "                realsense_camera_transform = np.array(row[1::]).astype(float).reshape((4,4))\n",
    "                realsense_human_poses = realsense_analyser.run(rgb_file, \n",
    "                                                   depth_file, \n",
    "                                                   realsense_camera_transform)\n",
    "\n",
    "                realsense_position_results.append([t_stamp] + realsense_human_poses)\n",
    "\n",
    "\n",
    "            with open(output_positions_dir + '/map{0}_run{1}_realsense.csv'.format(map_num, run), 'w') as myrealsensefile:\n",
    "                realsense_wr = csv.writer(myrealsensefile, quoting=csv.QUOTE_ALL)\n",
    "                for i in range(len(realsense_position_results)):\n",
    "                    realsense_wr.writerow(realsense_position_results[i])\n",
    "\n",
    "\n",
    "            print(\"Finished mapnum:{0} \\t run:{1}\".format(map_num, run))\n",
    "    # result = numpy.array(x).astype(\"float\")\n",
    "\n",
    "    #         for t_stamp in \n",
    "    #         [hsr_result, hsr_poses] = hsr_analyser.run(rgb_file, depth_file, hsr_camera_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd96985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
