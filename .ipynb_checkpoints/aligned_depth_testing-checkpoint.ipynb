{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import rospy\n",
    "from centermask.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2_ros.msg import Result\n",
    "from sensor_msgs.msg import Image, RegionOfInterest\n",
    "\n",
    "import centermask.modeling.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(param, default=None):\n",
    "    new_param = rospy.get_param(param, default)\n",
    "    rospy.loginfo(\"[Centermask2] %s: %s\", param, new_param)\n",
    "    return new_param\n",
    "\n",
    "def convert_to_cv_image(image_msg):\n",
    "\n",
    "    if image_msg is None:\n",
    "        return None\n",
    "\n",
    "    channels = int(len(image_msg.data) / (image_msg.width * image_msg.height))\n",
    "\n",
    "    encoding = None\n",
    "    if image_msg.encoding.lower() in ['rgb8', 'bgr8']:\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == 'mono8':\n",
    "        encoding = np.uint8\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "    # For depth images        \n",
    "        encoding = np.uint16\n",
    "        channels = 1\n",
    "    elif image_msg.encoding.lower() == '32fc1':\n",
    "        encoding = np.float32\n",
    "        channels = 1\n",
    "\n",
    "    cv_img = np.ndarray(shape=(image_msg.height, image_msg.width, channels),\n",
    "                        dtype=encoding, buffer=image_msg.data)\n",
    "\n",
    "    if image_msg.encoding.lower() == 'mono8':\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)\n",
    "    elif image_msg.encoding.lower() == '16uc1':\n",
    "        pass\n",
    "    else:\n",
    "        cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_img\n",
    "\n",
    "def getStaticDepthImage(depth_image, predictions, class_names):\n",
    "\n",
    "    static_depth_img = depth_image.copy()\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((15,15),np.uint8)\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "#         static_depth_img[masks[inds[i]]]=0\n",
    "        static_depth_img[(cv.dilate(np.float32(masks[inds[i]]),kernel,iterations = 2)).astype(bool)]=0\n",
    "\n",
    "    return static_depth_img\n",
    "\n",
    "\n",
    "def getResult(predictions, header, bridge, class_names):\n",
    "\n",
    "    boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "\n",
    "    if predictions.has(\"pred_masks\"):\n",
    "        masks = np.asarray(predictions.pred_masks)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    class_ids = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "    class_names = np.array(class_names)[class_ids.numpy()]\n",
    "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "    \n",
    "    arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "    inds = np.where(arr)[0]\n",
    "    \n",
    "    if len(inds)<1:\n",
    "        return\n",
    "    \n",
    "    result_msg = Result()\n",
    "    result_msg.header = header\n",
    "    result_msg.class_ids = class_ids[arr]\n",
    "    result_msg.class_names = class_names[arr]\n",
    "    result_msg.scores = scores[arr]\n",
    "\n",
    "#     for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "\n",
    "#     for i in inds:\n",
    "    for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "        mask = np.zeros(masks[i].shape, dtype=\"uint8\")\n",
    "        mask[masks[i, :, :]]=255\n",
    "        mask = bridge.cv2_to_imgmsg(mask)\n",
    "        result_msg.masks.append(mask)\n",
    "\n",
    "        box = RegionOfInterest()\n",
    "        box.x_offset = np.uint32(x1)\n",
    "        box.y_offset = np.uint32(y1)\n",
    "        box.height = np.uint32(y2 - y1)\n",
    "        box.width = np.uint32(x2 - x1)\n",
    "        result_msg.boxes.append(box)\n",
    "\n",
    "    return result_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import message_filters\n",
    "\n",
    "rospy.init_node('centermask2_ros')\n",
    "\n",
    "bridge = CvBridge()\n",
    "_last_rgb_msg = None\n",
    "_last_depth_msg = None\n",
    "_msg_lock = threading.Lock()\n",
    "_image_counter = 0\n",
    "\n",
    "cfg = get_cfg()\n",
    "# cfg.merge_from_file(load_param('~config'))\n",
    "# cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_V_99_eSE_FPN_ms_3x.yaml\")\n",
    "cfg.merge_from_file(\"/root/centermask2/configs/centermask/centermask_lite_V_39_eSE_FPN_ms_4x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = load_param('~detection_threshold') # set threshold for this model\n",
    "# cfg.MODEL.WEIGHTS = load_param('~model')\n",
    "# cfg.MODEL.WEIGHTS = \"/root/centermask2-V-99-eSE-FPN-ms-3x.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"/root/centermask2-lite-V-39-eSE-FPN-ms-4x.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "_class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).get(\"thing_classes\", None)\n",
    "\n",
    "_visualization = load_param('~visualization',True)\n",
    "_result_pub = rospy.Publisher('result', Result, queue_size=1)\n",
    "_vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)\n",
    "\n",
    "\n",
    "callback_init = False\n",
    "\n",
    "def callback_images(rgb_msg, depth_msg):\n",
    "    rospy.logdebug(\"Get an image\")\n",
    "    if _msg_lock.acquire(False):\n",
    "        _last_rgb_msg = rgb_msg\n",
    "        _last_depth_msg = depth_msg\n",
    "        _rgb_header = rgb_msg.header\n",
    "        _depth_header = depth_msg.header\n",
    "        _msg_lock.release()\n",
    "    callback_init = True\n",
    "        \n",
    "# _sub = rospy.Subscriber(load_param('~input'), Image, callback_image, queue_size=1)\n",
    "# _image_sub = rospy.Subscriber('/camera/color/image_raw', Image, callback_image, queue_size=1)\n",
    "# _depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw', Image, callback_image, queue_size=1)\n",
    "_image_sub = message_filters.Subscriber('/camera/color/image_raw', Image)\n",
    "_depth_sub = message_filters.Subscriber('/camera/aligned_depth_to_color/image_raw', Image)\n",
    "        \n",
    "ts = message_filters.ApproximateTimeSynchronizer([_image_sub, _depth_sub], 1, 0.003)\n",
    "ts.registerCallback(callback_images)\n",
    "        \n",
    "_last_rgb_msg = rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None)\n",
    "_last_depth_msg = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw', Image, timeout=None)\n",
    "\n",
    "\n",
    "_last_rgb_msg = rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None)\n",
    "_last_depth_msg = rospy.wait_for_message('/camera/aligned_depth_to_color/image_raw', Image, timeout=None)\n",
    "_rgb_header = _last_rgb_msg.header\n",
    "_depth_header = _last_depth_msg.header\n",
    "\n",
    "#     rospy.spinOnce()\n",
    "    \n",
    "np_image = convert_to_cv_image(_last_rgb_msg)\n",
    "np_depth_image = convert_to_cv_image(_last_depth_msg)\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = predictor(np_image)\n",
    "finish_time = time.time()\n",
    "print(\"Time to predict:\" + str(finish_time- start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "result = outputs[\"instances\"].to(\"cpu\")\n",
    "finish_time = time.time()\n",
    "print(\"CPU transfer:\" + str(finish_time- start_time))\n",
    "\n",
    "static_depth_img = getStaticDepthImage(np_depth_image, result, _class_names)\n",
    "\n",
    "start_time = time.time()\n",
    "result_msg = getResult(result, _rgb_header, bridge, _class_names)\n",
    "finish_time = time.time()\n",
    "print(\"Results msg time:\" + str(finish_time- start_time))\n",
    "\n",
    "_result_pub.publish(result_msg)\n",
    "\n",
    "# Visualize resultsresult_msg\n",
    "start_time = time.time()\n",
    "v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "image_msg = bridge.cv2_to_imgmsg(img)\n",
    "finish_time = time.time()\n",
    "print(\"Visualisation time:\" + str(finish_time- start_time))\n",
    "\n",
    "plt.imshow(img)\n",
    "# self._vis_pub.publish(image_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np_depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = result.pred_boxes if result.has(\"pred_boxes\") else None\n",
    "\n",
    "if result.has(\"pred_masks\"):\n",
    "    masks = np.asarray(result.pred_masks)\n",
    "\n",
    "class_ids = result.pred_classes if result.has(\"pred_classes\") else None\n",
    "class_names = np.array(_class_names)[class_ids.numpy()]\n",
    "scores = result.scores if result.has(\"scores\") else None\n",
    "\n",
    "arr = (class_names == 'person') & (scores.numpy() > 0.5)\n",
    "inds = np.where(arr)[0]\n",
    "\n",
    "# if len(inds)<1:\n",
    "#     return\n",
    "\n",
    "# for i, (x1, y1, x2, y2) in enumerate(boxes[arr]):\n",
    "#     static_depth_img[masks[inds[i]]]=0\n",
    "\n",
    "# return static_depth_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = masks[inds[0]]\n",
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_im = np_image.copy()\n",
    "rgb_im[a] = 0\n",
    "plt.imshow(rgb_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "kernel = np.ones((15,15),np.uint8)\n",
    "dilation = cv2.dilate(np.float32(a),kernel,iterations = 2)\n",
    "# np.float32(imgUMat)\n",
    "plt.imshow(dilation.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np_depth_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cpy = np_depth_image.copy()\n",
    "im_cpy[a] = 0\n",
    "plt.imshow(im_cpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(static_depth_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
